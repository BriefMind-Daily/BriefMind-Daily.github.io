标题,中文标题,领域分类,研究机构,PDF链接,论文链接,简明摘要,Upvote数
DeepAgent: A General Reasoning Agent with Scalable Toolsets,DeepAgent：具备可扩展工具集的一般推理智能体,Agent,Other,https://arxiv.org/pdf/2510.21618,https://huggingface.co/papers/2510.21618,本文提出了DeepAgent，一种端到端的深度推理智能体，能够自主进行思考、工具发现和动作执行，突破了传统预设流程的限制。为解决多工具调用带来的长时交互和记忆累积问题，设计了自主记忆折叠机制，有效压缩并保留关键信息。通过一种基于强化学习的新策略，DeepAgent实现了高效稳定的通用工具使用。大量实验表明，该智能体在多种工具使用和实际应用任务中均优于现有方法，推动了更通用且强大的智能体在现实场景中的应用。,55
Video-As-Prompt: Unified Semantic Control for Video Generation,Video-As-Prompt：用于视频生成的统一语义控制,Diffusion Model,ByteDance,https://arxiv.org/pdf/2510.20888,https://huggingface.co/papers/2510.20888,本文提出了Video-As-Prompt（VAP）方法，通过将参考视频作为语义提示，指导一个冻结的视频扩散模型实现统一且通用的语义控制视频生成。该方法避免了传统结构控制带来的伪影问题，无需针对特定条件进行微调，具备强大的零样本泛化能力。为支持该方法，作者构建了包含10万对视频及100种语义条件的大规模数据集VAP-Data。实验表明，VAP在开源模型中达到领先性能，用户偏好度达到38.7%，接近商业专用模型水平，推动了可控视频生成向通用化方向的发展。,28
"Sample By Step, Optimize By Chunk: Chunk-Level GRPO For Text-to-Image
  Generation",逐步采样，分块优化：用于文本到图像生成的分块级GRPO方法,Diffusion Model,THU,https://arxiv.org/pdf/2510.21583,https://huggingface.co/papers/2510.21583,本文提出了一种针对文本生成图像任务的新优化方法——Chunk-GRPO，通过将生成过程中的连续步骤划分为“块”进行整体优化，有效解决了传统方法中对各步骤奖励分配不准确及忽视生成过程时间动态的问题。该方法不仅提升了生成图像的质量和细节表现，还增强了与用户偏好的匹配度。大量实验验证了Chunk-GRPO在图像生成效果上的显著优势，展示了基于块级优化策略在文本到图像生成领域的潜力和应用价值。,24
"From Denoising to Refining: A Corrective Framework for Vision-Language
  Diffusion Model",从去噪到精炼：一种用于视觉-语言扩散模型的纠正框架,Diffusion Model,Tencent,https://arxiv.org/pdf/2510.19871,https://huggingface.co/papers/2510.19871,本文提出了ReDiff，一种改进的视觉语言离散扩散模型框架，通过将生成过程从被动的去噪转变为主动的修正，解决了训练与推理不一致导致的错误累积问题。该方法采用两阶段训练，首先教模型修正合成错误，再通过在线自我纠错循环，让模型学会改正自身生成的错误草稿。实验表明，ReDiff显著提升了生成内容的连贯性和准确性，实现了比传统去噪方法更稳定高效的并行生成，推动了视觉语言任务中扩散模型的实用性。,23
A Definition of AGI,AGI的定义,AGI,Other,https://arxiv.org/pdf/2510.18212,https://huggingface.co/papers/2510.18212,本文提出了一个基于人类认知理论的量化框架，旨在为人工通用智能（AGI）提供明确且可衡量的定义。该框架将通用智能划分为十个核心认知领域，通过改编人类心理测评方法来评估AI系统的能力。应用该框架发现，当前AI在知识密集型领域表现出色，但在基础认知能力，尤其是长期记忆方面存在显著不足。论文通过具体指标量化了当前AI与AGI之间的差距，为评估和推动AGI的发展提供了科学依据。,18
Sparser Block-Sparse Attention via Token Permutation,通过Token置换实现更稀疏的块稀疏注意力,LLM,ByteDance,https://arxiv.org/pdf/2510.21270,https://huggingface.co/papers/2510.21270,本文提出了一种名为Permuted Block-Sparse Attention（PBS-Attn）的新方法，通过重新排列输入序列中的令牌，提升了自注意力机制中块级稀疏性的利用效率，从而显著降低了大语言模型在处理长上下文时的计算成本。实验表明，PBS-Attn在保证模型准确度的同时，实现了比现有块稀疏方法更优的性能，并在长上下文预处理阶段达到了最高2.75倍的加速效果，展示了其在实际应用中的潜力和有效性。,17
"UI-Ins: Enhancing GUI Grounding with Multi-Perspective
  Instruction-as-Reasoning",UI-Ins：通过多视角指令即推理提升GUI定位能力,Agent,Alibaba,https://arxiv.org/pdf/2510.20286,https://huggingface.co/papers/2510.20286,本论文提出了“Instruction-as-Reasoning”范式，通过将用户指令视为多视角的动态推理路径，显著提升了图形用户界面（GUI）定位的准确性。作者发现现有数据集中指令存在较高错误率，且利用指令多样性可带来大幅性能提升。为此，设计了结合监督微调和强化学习的两阶段训练框架，使模型能够在推理时选择最优路径。所提出的UI-Ins系列模型在多个基准测试中取得领先成绩，展示了强大的推理能力和执行潜力，为智能GUI代理的发展提供了新的思路和方法。,16
Reasoning with Sampling: Your Base Model is Smarter Than You Think,基于采样的推理：你的基础模型比你想象的更智能,LLM,Other,https://arxiv.org/pdf/2510.14901,https://huggingface.co/papers/2510.14901,本文提出了一种基于迭代采样的简单算法，利用基础语言模型自身的概率分布，在无需额外训练的情况下显著提升模型的推理能力。该方法在多个单次推理任务上表现优异，甚至超越了依赖强化学习后训练的模型，同时避免了强化学习后常见的生成多样性下降问题。该算法不依赖训练数据或验证机制，展现出广泛的适用性，表明基础模型本身具备更强的推理潜力，挑战了强化学习作为提升推理能力唯一途径的传统观点。,16
WorldGrow: Generating Infinite 3D World,WorldGrow：生成无限扩展的三维世界,Embodied AI,Other,https://arxiv.org/pdf/2510.21682,https://huggingface.co/papers/2510.21682,本文提出了WorldGrow，一种分层框架，用于生成无限扩展的三维虚拟环境。该方法通过利用预训练3D模型的生成先验，结合高质量场景块的数据处理、基于上下文的3D块修补以及由粗到细的生成策略，实现了大规模连续场景的构建。WorldGrow不仅在几何重建上达到先进水平，还能生成结构合理、外观真实的无限场景，展示了其在虚拟环境构建和未来智能世界模型开发中的广泛应用潜力。,11
Visual Diffusion Models are Geometric Solvers,视觉扩散模型即几何求解器,Diffusion Model,DeepMind,https://arxiv.org/pdf/2510.21697,https://huggingface.co/papers/2510.21697,本文提出了一种将视觉扩散模型应用于几何问题求解的新方法。通过将几何问题转化为图像生成任务，模型从随机噪声逐步生成满足几何约束的图像，成功解决了包括内接正方形问题、斯坦纳树问题和简单多边形问题在内的多个复杂几何难题。该方法无需专门设计的结构或领域知识，展示了生成模型与几何推理之间的意外联系，开辟了利用图像空间处理复杂几何问题的全新方向，具有广泛的潜在应用价值。,11
"RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via
  Hierarchical Model Merging",RECALL：通过分层模型合并实现表示对齐的灾难性遗忘缓解,LLM,THU,https://arxiv.org/pdf/2510.20479,https://huggingface.co/papers/2510.20479,本文提出了RECALL，一种基于模型内部表示的持续学习框架，旨在解决大语言模型在多任务训练中遗忘旧知识的问题。RECALL通过分析不同模型层次的隐藏表示，计算模型间相似性，并采用分层参数融合策略，有效保持浅层的通用特征同时适应深层的任务特定知识。该方法无需访问历史数据或任务标签，能够无缝整合多领域知识，显著提升模型的知识保留和泛化能力。实验结果表明，RECALL在多个自然语言处理任务和持续学习场景中优于现有方法，提供了一种高效且可扩展的解决方案。,10
"RAPO++: Cross-Stage Prompt Optimization for Text-to-Video Generation via
  Data Alignment and Test-Time Scaling",RAPO++：通过数据对齐与测试时缩放实现文本到视频生成的跨阶段提示优化,Diffusion Model,Other,https://arxiv.org/pdf/2510.20206,https://huggingface.co/papers/2510.20206,本文提出了RAPO++，一种针对文本生成视频任务的跨阶段提示优化框架。该方法通过三个阶段依次丰富和调整用户输入的文本提示，使其更符合训练数据分布，并结合多源反馈进行迭代优化，最终利用大语言模型微调实现高效优质的提示生成。RAPO++无需改变底层生成模型，即可显著提升视频生成的语义一致性、内容组合能力和时间连贯性。大量实验验证了其在多个主流模型和数据集上的优越性能，展示了该方法作为一种通用、经济且可扩展的提示优化解决方案的潜力。,10
Map the Flow: Revealing Hidden Pathways of Information in VideoLLMs,Map the Flow：揭示VideoLLMs中信息的隐藏路径,Multimodal LLM,Other,https://arxiv.org/pdf/2510.13251,https://huggingface.co/papers/2510.13251,本文通过机制可解释性方法，揭示了视频大语言模型（VideoLLMs）在视频问答任务中信息流动的内部规律。研究发现，模型首先在早中层通过跨帧交互进行时间推理，随后在中层逐步实现视频与语言信息的融合，最终在中后层生成答案。基于此，模型能够通过选择有效的信息路径并抑制大量无关注意力连接，保持性能稳定。该工作为理解VideoLLMs的推理过程提供了清晰框架，有助于提升模型的可解释性和泛化能力。,9
Model Merging with Functional Dual Anchors,基于功能双锚点的模型合并,LLM,Other,https://arxiv.org/pdf/2510.21223,https://huggingface.co/papers/2510.21223,"本文提出了一种名为功能双锚（Functional Dual Anchors, FDAs）的模型合并方法，用于高效整合多个微调模型的知识。与传统基于参数空间的合并方法不同，FDAs通过在输入表示空间构建合成输入，使其梯度与任务向量对齐，从而更准确地捕捉任务特定的功能变化。该方法兼具鲁棒性和灵活性，并且与参数空间合并方法互补。实验结果表明，FDAs显著提升了模型合并的效果，为多任务知识整合提供了新的思路。",8
"PhysWorld: From Real Videos to World Models of Deformable Objects via
  Physics-Aware Demonstration Synthesis",PhysWorld：通过物理感知演示合成从真实视频到可变形物体世界模型的构建,Embodied AI,Other,https://arxiv.org/pdf/2510.21447,https://huggingface.co/papers/2510.21447,本文提出了PhysWorld，一种结合物理模拟与图神经网络的框架，用于构建可准确预测变形物体动态的交互式世界模型。通过在模拟器中创建物理一致的数字孪生体，并对其物理属性进行多样化扰动，生成丰富且合理的演示数据，进而训练轻量级模型。该方法不仅提升了预测精度，还实现了比现有先进方法快47倍的推理速度，且能有效适应新颖交互场景，推动了机器人、虚拟现实等领域对变形物体动态建模的应用发展。,2
"ARC-Encoder: learning compressed text representations for large language
  models",ARC-Encoder：用于大型语言模型的压缩文本表示学习,LLM,Other,https://arxiv.org/pdf/2510.20535,https://huggingface.co/papers/2510.20535,本文提出了ARC-Encoder，一种将文本上下文压缩为连续表示的编码器，用于替代大型语言模型（LLM）中的词元嵌入，从而显著减少输入长度。该方法无需微调或修改目标模型架构，避免了性能下降。通过系统研究训练策略和结构设计，ARC-Encoder实现了4到8倍的压缩率，在多种使用场景和模型上均表现出优异的性能和推理效率提升。此外，该编码器具备跨多种解码器模型的适应能力，提供了一种灵活高效的文本压缩解决方案。相关代码和预训练模型已公开。,2
Taming Modality Entanglement in Continual Audio-Visual Segmentation,驯服持续音视频分割中的模态纠缠,Multimodal LLM,Other,https://arxiv.org/pdf/2510.17234,https://huggingface.co/papers/2510.17234,本文提出了一项新的连续音视频分割任务，旨在通过声音指导实现对新类别的持续分割，解决多模态学习中细粒度任务的挑战。针对多模态语义漂移和频繁共现类别混淆两大问题，设计了基于冲突的多模态回放框架，包括多模态样本选择和冲突样本回放机制，有效提升了模型在连续学习中的表现。实验结果表明，该方法在多个增量场景下显著优于单模态学习方法，推动了多模态连续学习的发展。,2
"Are Large Reasoning Models Good Translation Evaluators? Analysis and
  Performance Boost",大型推理模型是优秀的翻译评估器吗？分析与性能提升,LLM,Other,https://arxiv.org/pdf/2510.20780,https://huggingface.co/papers/2510.20780,本文首次系统分析了大型推理模型（LRMs）在机器翻译质量评估中的应用，发现其在处理简单实例时易出现“过度思考”及评分偏高的问题。为此，作者提出通过训练模型模拟人类思维轨迹来校准其推理过程。实验证明，该方法在WMT24评测中显著降低了计算成本（约35倍），同时提升了评估准确性，适用于不同规模的模型。研究表明，经过高效校准的LRMs具备推动细粒度自动翻译评估的潜力。,2
"Document Understanding, Measurement, and Manipulation Using Category
  Theory",利用范畴论进行文档理解、测量与操作,Multimodal LLM,Other,https://arxiv.org/pdf/2510.21553,https://huggingface.co/papers/2510.21553,本文提出了一种基于范畴论的文档结构表示方法，将文档视为问题-答案对的集合，从而实现对文档信息的系统划分和度量。基于此结构，作者发展了新的信息测量、内容摘要及文档扩展技术，并提出了一种自监督学习方法，通过一致性约束提升大型预训练模型的性能。此外，方法支持多模态文档处理，体现了理论框架在文档理解和操作上的广泛适用性与创新价值。,2
"AstaBench: Rigorous Benchmarking of AI Agents with a Scientific Research
  Suite",AstaBench：基于科学研究套件的AI智能体严格基准测试,Agent,Other,https://arxiv.org/pdf/2510.21652,https://huggingface.co/papers/2510.21652,本文提出了AstaBench，一个面向科学研究的AI代理评测套件，涵盖2400多个真实科学问题，覆盖科学发现的全过程和多个领域。AstaBench提供了首个具备生产级搜索工具的科学研究环境，实现了对AI代理能力的严格、可重复评测，有效控制了模型成本和工具访问等干扰因素。通过评测57个代理，研究发现尽管AI在部分任务上已有进展，但距离全面辅助科学研究仍有较大差距。该工作为推动科学领域AI代理的实际应用和性能提升提供了重要基准和工具支持。,2
Foley Control: Aligning a Frozen Latent Text-to-Audio Model to Video,Foley Control：将冻结的潜在文本到音频模型与视频对齐,Multimodal LLM,Other,https://arxiv.org/pdf/2510.21581,https://huggingface.co/papers/2510.21581,本文提出了Foley Control，一种轻量级的视频驱动音效生成方法。该方法通过保持预训练的文本到音频模型和视频编码器不变，仅学习一个小型的跨注意力模块，实现视频与音频的同步对齐。Foley Control在保证语义和时间同步准确性的同时，大幅减少了需要训练的参数量，且保持了系统的模块化设计，方便替换或升级各部分组件。实验表明，该方法在视频音频对齐任务中表现出竞争力，且具备良好的生产适用性，未来可扩展至其他音频生成领域。,1
Soft Instruction De-escalation Defense,软指令降级防御,Agent,DeepMind,https://arxiv.org/pdf/2510.21057,https://huggingface.co/papers/2510.21057,本文提出了一种名为Soft Instruction Control（SIC）的防御方法，旨在提升基于大型语言模型（LLM）的智能代理系统对抗提示注入攻击的安全性。该方法通过多轮循环检测和清理输入数据中的潜在恶意指令，反复重写或屏蔽可疑内容，直到输入无害或达到最大迭代次数，确保代理行为不被恶意操控。实验表明，虽然SIC无法完全杜绝所有攻击，但显著提高了攻击难度，降低了系统风险，为实际应用中的安全防护提供了一种有效且实用的解决方案。,1
"ALICE-LRI: A General Method for Lossless Range Image Generation for
  Spinning LiDAR Sensors without Calibration Metadata",ALICE-LRI：一种无需校准元数据的旋转式激光雷达传感器无损距离图生成通用方法,Other,Other,https://arxiv.org/pdf/2510.20708,https://huggingface.co/papers/2510.20708,本文提出了ALICE-LRI，一种无需厂商校准数据即可实现旋转式激光雷达点云无损二维投影的方法。该方法通过自动推断激光雷达的内部几何参数，实现了点云到二维距离图的无信息丢失转换，保证了点的完整保留和几何精度。实验验证表明，ALICE-LRI在多个公开数据集上实现了零点损失和高精度重建，且具备实时性能。此外，该方法在数据压缩等实际应用中表现出显著优势，为高精度遥感和自动驾驶等领域提供了新的技术路径。,1
"PhysVLM-AVR: Active Visual Reasoning for Multimodal Large Language
  Models in Physical Environments",PhysVLM-AVR：物理环境中多模态大语言模型的主动视觉推理,Multimodal LLM,Tencent,https://arxiv.org/pdf/2510.21111,https://huggingface.co/papers/2510.21111,本文提出了主动视觉推理（AVR）任务，旨在扩展多模态大语言模型在部分可观测、交互式环境中的视觉推理能力。为此，作者设计了CLEVR-AVR基准和包含丰富推理过程注释的大规模数据集AVR-152k，用于训练和评估模型在信息获取与整合上的表现。基于此，开发了PhysVLM-AVR模型，在多项视觉推理任务中取得领先成绩。研究还揭示了当前模型在主动探索和动态调整决策方面的不足，指出了未来提升智能体主动推理能力的方向。,0
"Stabilizing MoE Reinforcement Learning by Aligning Training and
  Inference Routers",通过对齐训练与推理路由器稳定MoE强化学习,LLM,PKU,https://arxiv.org/pdf/2510.11370,https://huggingface.co/papers/2510.11370,本论文针对混合专家模型（MoE）在强化学习训练中因路由机制不一致导致的不稳定性问题，提出了一种名为Rollout Routing Replay（R3）的方法。该方法通过记录推理阶段的路由分布并在训练时重放，显著减少训练与推理之间的差异，从而稳定训练过程，避免训练崩溃。大量实验表明，R3在提升训练稳定性和性能方面优于现有方法，为MoE模型中的强化学习训练提供了有效解决方案。,0

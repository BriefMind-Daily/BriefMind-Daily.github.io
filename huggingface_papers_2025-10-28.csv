标题,中文标题,领域分类,研究机构,PDF链接,论文链接,简明摘要,Upvote数
"Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial
  Representations",Concerto：联合2D-3D自监督学习下的空间表征生成,Other,Other,https://arxiv.org/pdf/2510.23607,https://huggingface.co/papers/2510.23607,本文提出了Concerto，一种结合3D自蒸馏与2D-3D联合嵌入的简约自监督学习模型，模拟人类通过多感官协同形成空间认知的过程。Concerto能够学习更连贯且信息丰富的空间特征，在多个三维场景理解任务中显著优于现有单模态和多模态自监督方法，表现出更细致的几何和语义一致性。此外，作者还扩展了Concerto以适应视频点云理解，并设计了将其表示映射到语言空间的转换器，实现开放世界感知。该工作为无监督空间表示学习提供了有效的新范式。,139
ReCode: Unify Plan and Action for Universal Granularity Control,ReCode：统一计划与行动以实现通用粒度控制,Agent,Other,https://arxiv.org/pdf/2510.23564,https://huggingface.co/papers/2510.23564,本文提出了ReCode，一种将高层规划与低层执行统一于单一代码表示的递归生成范式。通过将高层计划视为抽象函数并递归细化为具体动作，ReCode打破了传统方法中规划与执行的界限，实现了灵活的决策粒度控制。该方法不仅提升了模型的推理性能和训练数据效率，还自然生成多层级训练数据，促进了层次化决策能力的学习。实验证明，ReCode在多任务场景中表现优异，为智能体实现通用粒度控制提供了有效路径。,93
A Survey of Data Agents: Emerging Paradigm or Overstated Hype?,数据智能体综述：新兴范式还是被夸大的炒作？,Agent,Other,https://arxiv.org/pdf/2510.23587,https://huggingface.co/papers/2510.23587,本文针对“数据代理”这一新兴概念存在的定义模糊和能力混淆问题，提出了首个系统性的分层分类体系，将数据代理按自主程度划分为六个等级，从完全人工操作到完全自主生成，明确了各级别的功能边界和责任分配。基于此框架，文章系统回顾了现有研究进展，分析了关键技术挑战，尤其是从部分自主向条件自主的转变。最后，论文展望了未来主动、生成型数据代理的发展方向，为相关领域的研究与应用提供了清晰指导和参考。,47
FARMER: Flow AutoRegressive Transformer over Pixels,FARMER：基于像素的流式自回归变换器,Other,ByteDance,https://arxiv.org/pdf/2510.23588,https://huggingface.co/papers/2510.23588,本文提出了FARMER，一种结合正则化流和自回归模型的生成框架，能够直接从原始像素数据中高效地估计图像分布的精确概率并生成高质量图像。通过引入可逆自回归流将图像转换为潜在序列，并利用自监督方法减少冗余维度，FARMER有效缓解了像素级建模的复杂性。此外，设计的一步蒸馏加速推理过程，结合无分类器引导策略提升生成效果。实验结果表明，FARMER在保持精确似然计算的同时，实现了与现有像素级生成模型相当甚至更优的性能，具备良好的训练和推理可扩展性。,40
"VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing,
  Speaking, and Acting",VITA-E：具身AI中实现视觉、听觉、语言和动作的并发自然交互,Embodied AI,Tencent,https://arxiv.org/pdf/2510.21817,https://huggingface.co/papers/2510.21817,本文提出了VITA-E，一种创新的人机交互框架，支持机器人同时进行视觉感知、语音识别、语言交流和动作执行，并能实时响应用户的中断指令。通过双模型架构实现“主动模型”和“待命模型”并行工作，机器人能够像人类一样多任务处理，显著提升交互的自然性和灵活性。实验证明，该框架在复杂场景下表现稳定，具备高效的紧急停止和语音中断响应能力，推动了更智能、更灵活的机器人助理发展。,38
"Lookahead Anchoring: Preserving Character Identity in Audio-Driven Human
  Animation",Lookahead Anchoring：音频驱动人类动画中的角色身份保持,Embodied AI,Other,https://arxiv.org/pdf/2510.23581,https://huggingface.co/papers/2510.23581,本文提出了一种名为“前瞻锚定”的方法，解决了音频驱动的人物动画在连续生成过程中角色身份逐渐丧失的问题。该方法通过利用未来时间点的关键帧作为动态指导，使模型在响应当前音频的同时，持续向未来目标靠拢，从而保持角色身份的一致性。相比传统关键帧生成，前瞻锚定无需额外生成步骤，且能灵活调节动作表现与身份保持的平衡。实验证明，该方法显著提升了唇同步效果、身份保持和视觉质量，适用于多种动画模型，推动了音频驱动人类动画的长期稳定生成。,36
ACG: Action Coherence Guidance for Flow-based VLA models,ACG：基于流模型的视觉-语言-动作（VLA）模型的动作连贯性引导,Embodied AI,Other,https://arxiv.org/pdf/2510.22201,https://huggingface.co/papers/2510.22201,本文提出了一种名为动作连贯性引导（ACG）的算法，旨在提升基于视觉-语言-动作模型的机器人操作的动作连贯性。现有模型在模仿学习过程中容易受到示范中动作抖动和停顿的影响，导致动作不稳定和轨迹偏移，影响精细操作的准确性。ACG作为一种无需额外训练的测试阶段引导方法，有效增强了动作的平滑性和一致性，从而显著提高了机器人在多种操作任务中的成功率。实验证明该方法在多个模拟和真实环境中均表现出稳定的性能提升。,30
"IGGT: Instance-Grounded Geometry Transformer for Semantic 3D
  Reconstruction",IGGT：基于实例的几何变换器用于语义三维重建,Other,THU,https://arxiv.org/pdf/2510.22706,https://huggingface.co/papers/2510.22706,本论文提出了Instance-Grounded Geometry Transformer（IGGT），一种统一的端到端框架，将3D几何重建与实例级语义理解结合，通过仅使用二维视觉输入，实现对复杂场景的统一表示。为支持该方法，作者构建了大规模高质量数据集InsScene-15K，包含丰富的RGB图像、深度图及一致的实例掩码标注。IGGT采用3D一致性对比学习，有效提升了三维场景的重建精度和实例识别能力，促进了空间追踪、开放词汇分割和场景定位等多种下游应用，突破了传统方法在几何与语义理解分离上的局限。,26
"E^2Rank: Your Text Embedding can Also be an Effective
  and Efficient Listwise Reranker",E^2Rank：你的文本嵌入也可以成为高效且有效的列表式重排序器,LLM,Alibaba,https://arxiv.org/pdf/2510.22733,https://huggingface.co/papers/2510.22733,本文提出了E²Rank，一种基于单一文本嵌入模型的统一框架，能够同时高效完成文档检索和列表式重排序任务。通过继续训练并采用列表式排序目标，E²Rank利用查询与候选文档的嵌入向量余弦相似度作为统一排序函数，结合类似伪相关反馈的增强查询提示，有效提升了重排序性能。实验证明，E²Rank在多个基准测试中取得了领先效果，同时保持极低的延迟，展示了嵌入模型在兼顾效率与准确性方面的潜力，为检索与排序任务提供了简洁高效的解决方案。,25
"Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with
  Free-Form Preferences",Omni-Reward：面向通用多模态奖励建模的自由形式偏好方法,Multimodal LLM,Other,https://arxiv.org/pdf/2510.23451,https://huggingface.co/papers/2510.23451,本文提出了Omni-Reward，一种面向多模态和自由形式偏好的通用奖励模型框架，旨在解决现有奖励模型在模态支持不足和偏好表达单一上的局限。作者构建了涵盖文本、图像、视频、音频和3D五种模态的首个多模态奖励模型评测基准Omni-RewardBench，并收集了大规模多模态偏好数据集Omni-RewardData用于训练。同时，设计了包含判别式和生成式模型的Omni-RewardModel，实验证明其在多模态奖励建模任务中表现优异。该工作推动了更广泛模态和更灵活偏好表达的奖励模型发展，有助于提升人工智能对人类多样化需求的适应能力。,22
Knocking-Heads Attention,Knocking-Heads Attention（敲击头注意力机制）,LLM,Other,https://arxiv.org/pdf/2510.23052,https://huggingface.co/papers/2510.23052,本文提出了一种名为Knocking-Heads Attention（KHA）的改进多头注意力机制，通过允许不同注意力头之间进行特征级别的交互，克服了传统多头注意力中各头独立处理、缺乏协同的问题。KHA采用共享且对角线初始化的投影矩阵，既保留了各头的专属能力，又逐步学习头间整合表示。该方法仅带来极少的额外计算开销，能无缝应用于多种注意力变体。实验证明，KHA在大规模语言模型训练中提升了训练稳定性和下游任务表现，展现出较强的实用价值。,21
"PixelRefer: A Unified Framework for Spatio-Temporal Object Referring
  with Arbitrary Granularity",PixelRefer：一个支持任意粒度时空对象指代的统一框架,Multimodal LLM,Alibaba,https://arxiv.org/pdf/2510.23603,https://huggingface.co/papers/2510.23603,本文提出了PixelRefer，一种统一的多模态大语言模型框架，专注于图像和视频中用户指定区域的细粒度对象理解。通过引入自适应尺度的对象编码器和融合全局上下文的模块，PixelRefer能够生成紧凑且语义丰富的对象表示，实现高效且准确的对象级推理。作者还构建了大规模高质量的对象指令数据集，支持模型的精细调优。实验表明，PixelRefer在多个基准测试中表现优异，且轻量版PixelRefer-Lite在保持准确度的同时显著提升了计算效率，推动了细粒度视觉理解的发展。,19
"The Best of N Worlds: Aligning Reinforcement Learning with Best-of-N
  Sampling via max@k Optimisation",多世界最佳：通过max@k优化将强化学习与Best-of-N采样对齐,LLM,Other,https://arxiv.org/pdf/2510.23393,https://huggingface.co/papers/2510.23393,本文提出了一种针对大型语言模型在“Best-of-N”采样策略下表现优化的新方法。通过引入并优化max@k指标，这一方法有效提升了模型生成结果的多样性和质量。作者推导了无偏的梯度估计公式，支持在强化学习中的在线和离线更新，增强了样本利用效率。实验证明，该方法能更好地对齐模型训练与推理策略，显著改善了在数学和编程任务中的推理与解题能力。该研究为提升基于验证奖励的强化学习模型性能提供了新的理论和实践工具。,12
"LightBagel: A Light-weighted, Double Fusion Framework for Unified
  Multimodal Understanding and Generation",LightBagel：一种轻量级双重融合框架，用于统一的多模态理解与生成,Multimodal LLM,"ByteDance, THU",https://arxiv.org/pdf/2510.22946,https://huggingface.co/papers/2510.22946,本文提出了LightBagel，一种轻量级的统一多模态理解与生成框架。该方法通过巧妙融合现有专门用于生成和理解的模型，采用双重融合机制在网络中交错引入多模态自注意力模块，实现了高效且丰富的多模态信息整合。相比从零训练的模型，LightBagel在仅使用约350亿训练标注下，依然在多个文本生成图像及图像编辑任务中取得了优异表现。论文公开了完整代码和模型，推动统一多模态模型的研究与应用。,10
LongCat-Video Technical Report,LongCat-Video 技术报告,Diffusion Model,Other,https://arxiv.org/pdf/2510.22200,https://huggingface.co/papers/2510.22200,本文介绍了LongCat-Video，一款拥有136亿参数的视频生成模型，基于扩散变换器架构，支持文本到视频、图像到视频及视频续作等多种任务。该模型通过预训练和多奖励强化学习，实现了高效且高质量的长视频生成，能够生成720p、30帧的分钟级视频，并保持良好的时序连贯性。采用粗到细生成策略和稀疏注意力机制显著提升了推理效率。LongCat-Video在多个视频生成任务中表现优异，模型代码和权重已公开，有助于推动视频生成领域的发展。,8
LimRank: Less is More for Reasoning-Intensive Information Reranking,LimRank：推理密集型信息重排序中的少即是多,LLM,Other,https://arxiv.org/pdf/2510.23544,https://huggingface.co/papers/2510.23544,本文提出了LIMRANK，一种基于少量高质量合成数据微调的大型语言模型信息重排序方法。通过设计开源的数据生成流程LIMRANK-SYNTHESIZER，作者生成了多样且具挑战性的训练样本，用以微调重排序模型。实验结果表明，LIMRANK在两个复杂的推理密集型检索任务上表现出与传统大规模训练方法相当的效果，但所需训练数据量不到以往的5%。此外，LIMRANK展现了良好的泛化能力，适用于科学文献检索及知识密集型生成等多种下游应用，体现了“少即是多”的有效策略。,6
Code Aesthetics with Agentic Reward Feedback,基于Agentic奖励反馈的代码美学,Agent,"Microsoft, PKU",https://arxiv.org/pdf/2510.23272,https://huggingface.co/papers/2510.23272,本文提出了一种提升大语言模型（LLM）生成代码美学质量的新方法。研究团队构建了大规模的美学指导数据集AesCode-358K，并设计了一个多智能体系统，通过评估代码的可执行性和视觉美感，提供反馈信号。基于此，开发了结合功能性和美学优化的训练算法GRPO-AR，并推出了评估代码美学的新基准OpenDesign。实验表明，该方法显著提升了代码的视觉质量和功能表现，且所训练模型AesCoder-4B在多个测试中优于现有先进模型，展示了其在视觉导向编码任务中的应用潜力。,6
"Distilled Decoding 2: One-step Sampling of Image Auto-regressive Models
  with Conditional Score Distillation",Distilled Decoding 2：基于条件分数蒸馏的图像自回归模型一步采样方法,Other,"Microsoft, THU",https://arxiv.org/pdf/2510.21003,https://huggingface.co/papers/2510.21003,本文提出了Distilled Decoding 2（DD2）方法，实现了图像自回归模型的一步采样，显著提升生成速度的同时仅带来极小的性能损失。相比之前的DD1方法，DD2不依赖预定义映射，而是通过条件得分蒸馏训练一个独立网络，准确预测生成分布的条件得分。实验证明，DD2在ImageNet-256数据集上实现了8到238倍的采样速度提升，且生成质量仅略有下降，显著缩小了一步采样与原模型性能的差距。该方法为快速且高质量的图像自回归生成开辟了新的可能。,5
"RobotArena infty: Scalable Robot Benchmarking via Real-to-Sim
  Translation",RobotArena infty：通过真实到模拟转换实现可扩展的机器人基准测试,Embodied AI,Other,https://arxiv.org/pdf/2510.23571,https://huggingface.co/papers/2510.23571,本文提出了RobotArena infty，一个通过将真实机器人操作视频自动转换为大规模模拟环境的基准测试框架，解决了现实环境中机器人策略评估的效率低、安全性差和难以复现等问题。该方法结合视觉语言模型和人类在线反馈，实现对机器人多任务策略的自动评分与偏好判断，并通过系统扰动模拟环境测试策略的鲁棒性。该框架具备可扩展性和持续演进能力，为真实训练的机器人操作策略提供了标准化、可重复且大规模的评价手段，填补了当前机器人评测领域的重要空白。,4
Language Server CLI Empowers Language Agents with Process Rewards,Language Server CLI通过过程奖励赋能语言智能体,Agent,Other,https://arxiv.org/pdf/2510.22907,https://huggingface.co/papers/2510.22907,本文提出了Lanser-CLI，一种基于命令行界面的语言服务器协调层，旨在提升编程智能体与持续集成中的代码处理能力。Lanser-CLI通过稳定且可重放的工作流程，利用语言服务器提供的精确信息（如代码定义、引用和诊断），为智能体的计划执行过程提供机器验证的反馈信号，称为“过程奖励”。该系统引入了更鲁棒的代码定位方法、规范化的分析数据包、安全的代码变更机制以及可在线计算和离线回放的奖励函数，确保操作的确定性和安全性。此方法有效减少了语言模型在代码理解与修改中的错误，提高了智能体的实际编码可靠性。,3
VoMP: Predicting Volumetric Mechanical Property Fields,VoMP：预测体积机械性能场,AI4Science,Other,https://arxiv.org/pdf/2510.22975,https://huggingface.co/papers/2510.22975,本文提出了VoMP，一种基于几何变换器的前馈模型，能够快速准确地预测三维物体内部的机械属性分布，包括杨氏模量、泊松比和密度。VoMP通过融合多视角体素特征，生成物理合理的材料表示，保证预测结果的真实性。为训练模型，作者设计了结合三维数据集、材料数据库和视觉语言模型的自动标注流程，并构建了新的基准测试。实验结果表明，VoMP在预测精度和计算速度上均显著优于现有方法，有助于提升真实感物理模拟的效率和可靠性。,2
"EchoDistill: Bidirectional Concept Distillation for One-Step Diffusion
  Personalization",EchoDistill：用于一步扩散个性化的双向概念蒸馏,Diffusion Model,Other,https://arxiv.org/pdf/2510.20512,https://huggingface.co/papers/2510.20512,本文提出了EchoDistill，一种双向概念蒸馏框架，用于提升一步生成的文本到图像扩散模型的个性化能力。该方法通过同时训练多步扩散模型（教师）和一步扩散模型（学生），实现概念的相互蒸馏与反馈，确保语义一致性并优化生成质量。EchoDistill不仅增强了学生模型对新概念的快速适应能力，还提升了教师模型的生成效果。实验证明，该框架在个性化任务上显著优于现有方法，为快速高效的文本到图像个性化生成提供了新的思路。,2
DiffusionLane: Diffusion Model for Lane Detection,DiffusionLane：基于扩散模型的车道线检测,Diffusion Model,Other,https://arxiv.org/pdf/2510.22236,https://huggingface.co/papers/2510.22236,本文提出了DiffusionLane，一种基于扩散模型的车道线检测方法。该方法通过向真实车道参数添加高斯噪声，生成带噪车道锚点，模型逐步对其进行优化以恢复准确车道线。为提升特征表达能力，设计了结合全局与局部信息的混合解码器，并在训练中引入辅助网络增强编码器监督。实验证明，DiffusionLane在多个主流数据集上表现优异，具备良好的泛化能力，显著超越现有方法，展现了其在自动驾驶车道检测中的应用潜力。,2
Scaling Laws for Deepfake Detection,深度伪造检测的规模定律,Other,DeepMind,https://arxiv.org/pdf/2510.16320,https://huggingface.co/papers/2510.16320,本文构建了迄今最大规模的深度伪造检测数据集ScaleDF，包含超过580万张真实图像和880万张由102种生成方法制作的伪造图像。基于该数据集，研究发现深度伪造检测模型的误差率随着真实图像领域数量和伪造方法数量的增加呈现可预测的幂律下降趋势。这一发现不仅有助于预测所需数据规模以达到特定性能，还为通过数据多样性应对不断演进的伪造技术提供了新思路。此外，论文还探讨了预训练和数据增强在模型性能提升中的作用及规模扩展的局限性，为深度伪造检测的未来研究提供了重要参考。,2
MARS-M: When Variance Reduction Meets Matrices,MARS-M：当方差缩减遇上矩阵,LLM,Other,https://arxiv.org/pdf/2510.21800,https://huggingface.co/papers/2510.21800,本文提出了一种名为MARS-M的新型优化器，将矩阵预处理技术Muon与方差减少方法MARS相结合，以提升大规模神经网络训练效率。在理论上，MARS-M较Muon实现了更快的收敛速度。实验证明，MARS-M在语言模型和计算机视觉任务中均表现出更低的训练损失和更优的性能，展示了其在实际应用中的有效性和广泛适用性。相关代码已公开，便于进一步研究与应用。,1
"PRISM-Bench: A Benchmark of Puzzle-Based Visual Tasks with CoT Error
  Detection",PRISM-Bench：基于链式思维错误检测的谜题视觉任务基准,Multimodal LLM,Other,https://arxiv.org/pdf/2510.23594,https://huggingface.co/papers/2510.23594,本文提出了PRISM-Bench，一个基于视觉谜题的评测基准，旨在考察多模态大语言模型不仅能否给出正确答案，更能否识别推理过程中的错误。该基准通过让模型在包含单一错误的逐步推理链中定位首个错误步骤，细致评估其逻辑一致性和视觉推理能力。实验结果显示，现有模型虽然能生成流畅的推理过程，但常难以发现简单的逻辑错误。PRISM-Bench为多模态推理能力提供了更精准的诊断工具，推动可信AI系统的发展。,1
"Track, Inpaint, Resplat: Subject-driven 3D and 4D Generation with
  Progressive Texture Infilling","Track, Inpaint, Resplat：基于渐进式纹理填充的主体驱动3D与4D生成",Other,Other,https://arxiv.org/pdf/2510.23605,https://huggingface.co/papers/2510.23605,"本文提出了一种名为TIRE（Track, Inpaint, Resplat）的新方法，旨在提升3D和4D生成中对特定主体身份的保真度。该方法通过视频跟踪识别需修改的区域，利用主体驱动的二维修补技术逐步填充纹理，最后将修改后的多视角图像重新映射回三维模型，实现身份信息的有效保持。实验结果表明，TIRE在保持生成内容与原始主体一致性方面显著优于现有技术，为个性化3D/4D生成提供了有效解决方案。",1
"Mitigating Attention Sinks and Massive Activations in Audio-Visual
  Speech Recognition with LLMS",利用大语言模型缓解音视频语音识别中的注意力汇聚与大规模激活问题,Multimodal LLM,Other,https://arxiv.org/pdf/2510.22603,https://huggingface.co/papers/2510.22603,本文首次在多模态语音识别中发现并分析了“注意力汇聚”现象，即某些无语义信息的标记在模型中吸引过度关注并引发异常激活。研究表明，这些异常激活主要源自模型的多层感知器层，且与起始标记高度相似，导致注意力和激活的放大。基于此，作者提出了一种简单的去相关损失，有效减少了标记间的相似性，从而缓解了异常现象。该方法在高特征降采样条件下显著提升了识别准确率，且在低降采样时保持稳定，推动了音视频语音识别模型的性能与理解。,1
"Memory-based Language Models: An Efficient, Explainable, and
  Eco-friendly Approach to Large Language Modeling",基于记忆的语言模型：一种高效、可解释且环保的大语言模型方法,LLM,Other,https://arxiv.org/pdf/2510.22317,https://huggingface.co/papers/2510.22317,本文提出了一种基于记忆的语言建模方法，作为深度神经网络语言模型的高效、环保替代方案。该方法通过快速近邻搜索实现下一个词的预测，具备良好的扩展性和强大的记忆能力，且在训练和推理过程中对计算资源需求低，主要依赖CPU，减少了碳排放。作者实现了该方法的系统OLIFANT，并与主流模型GPT-2和GPT-Neo在预测准确率、速度和能耗方面进行了对比，展示了其在性能和可解释性上的优势。,1
"SyncHuman: Synchronizing 2D and 3D Generative Models for Single-view
  Human Reconstruction",SyncHuman：用于单视图人体重建的二维与三维生成模型同步方法,Diffusion Model,PKU,https://arxiv.org/pdf/2510.07723,https://huggingface.co/papers/2510.07723,本文提出了SyncHuman，一种创新框架，通过同步结合二维多视角和三维生成模型，实现了从单张图片高质量、逼真地重建穿着服饰的人体三维网格。该方法利用二维模型细致捕捉图像细节，三维模型保证结构一致性，二者通过像素级同步机制和特征注入相互融合，显著提升了复杂姿态下的重建精度和细节表现。大量实验验证了SyncHuman在几何准确性和视觉真实感方面优于现有方法，展示了其在影视、游戏等领域的广泛应用潜力。,1
Redefining Retrieval Evaluation in the Era of LLMs,在大语言模型时代重新定义检索评估,LLM,Other,https://arxiv.org/pdf/2510.21440,https://huggingface.co/papers/2510.21440,本文针对传统信息检索评价指标在面向大型语言模型（LLM）的检索增强生成系统（RAG）中的不足，提出了一种新的评价方法。传统指标假设用户按顺序浏览文档且忽略无关内容，但LLM会整体处理所有检索结果，且无关文档会降低生成质量。为此，作者设计了一个基于文档正负效用的标注体系，并提出了UDCG指标，结合LLM特点调整文档权重，从而更准确反映检索结果对最终答案质量的影响。实验显示，UDCG较传统指标在预测系统性能上提升显著，有助于更合理地评估RAG系统表现。,0

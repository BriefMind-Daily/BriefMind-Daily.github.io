标题,中文标题,领域分类,研究机构,PDF链接,论文链接,简明摘要,Upvote数
Emu3.5: Native Multimodal Models are World Learners,Emu3.5：原生多模态模型是世界学习者,Multimodal LLM,Other,https://arxiv.org/pdf/2510.26583,https://huggingface.co/papers/2510.26583,本文提出了Emu3.5，一种大规模多模态世界模型，能够自然处理视觉与语言的交互输入和输出。该模型通过端到端训练，利用包含超过10万亿视觉语言混合数据的海量视频序列，统一预测下一状态，实现跨模态的长时序生成和复杂图文生成。通过引入离散扩散适配技术，显著提升推理速度约20倍而不损失性能。Emu3.5展现出强大的多模态理解和生成能力，支持时空一致的世界探索及多场景开放式任务执行，在图像生成和编辑任务中表现优异，且已开源以促进社区研究。,52
The End of Manual Decoding: Towards Truly End-to-End Language Models,手动解码的终结：迈向真正的端到端语言模型,LLM,Tencent,https://arxiv.org/pdf/2510.26697,https://huggingface.co/papers/2510.26697,本文提出了一种名为AutoDeco的新型语言模型架构，解决了当前大规模语言模型生成过程中需手动调节解码参数的问题。AutoDeco通过在模型中动态预测每一步的采样参数，实现了真正意义上的端到端文本生成，自动调控生成策略。实验表明，该方法在多个任务上显著优于传统固定参数解码，且性能接近经过人工调优的最佳方案。此外，模型还能理解自然语言指令，灵活调整生成风格，开启了可控且交互式语言生成的新方向。,47
Exploring Conditions for Diffusion models in Robotic Control,机器人控制中扩散模型条件的探索,Embodied AI,Other,https://arxiv.org/pdf/2510.15510,https://huggingface.co/papers/2510.15510,本文提出了一种基于预训练文本到图像扩散模型的机器人控制方法，旨在获得适应具体任务的视觉表示，而无需对模型进行微调。研究发现，直接使用文本条件在机器人控制中效果有限，主要因训练数据与控制环境存在差异。为此，作者设计了ORCA，通过引入可学习的任务提示和视觉提示，有效捕捉动态细节，实现视觉表示的任务适应性。该方法在多个机器人控制基准测试中表现优异，显著超越现有技术，推动了扩散模型在机器人控制领域的应用。,34
"Kimi Linear: An Expressive, Efficient Attention Architecture",Kimi Linear：一种表现力强且高效的注意力架构,LLM,Other,https://arxiv.org/pdf/2510.26692,https://huggingface.co/papers/2510.26692,本文提出了Kimi Linear，一种高效且表现优异的混合线性注意力架构。核心模块Kimi Delta Attention通过细粒度门控机制优化有限状态记忆的利用，结合专门设计的算法显著降低计算量。实验证明，Kimi Linear在多种任务和上下文长度下均超越传统全注意力机制，显著提升推理速度并减少缓存需求。该架构可作为全注意力模型的高效替代方案，特别适合长序列处理和强化学习场景。作者还开源了相关代码和预训练模型，促进后续研究。,28
"Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with
  the MME-CoF Benchmark",视频模型准备好作为零样本推理器了吗？基于MME-CoF基准的实证研究,Other,PKU,https://arxiv.org/pdf/2510.26802,https://huggingface.co/papers/2510.26802,本文通过构建MME-CoF基准，对领先的视频生成模型Veo-3在零-shot视觉推理能力进行系统评估。研究涵盖空间、几何、物理、时间及逻辑等12个维度，揭示该模型在短期空间一致性和局部动态推理上表现良好，但在长时因果推理、严格几何约束及抽象逻辑方面仍存在显著不足。结果表明，目前视频模型尚不能作为独立的零-shot推理工具，但具备作为辅助视觉引擎与专门推理模型结合的潜力，推动了视频模型在视觉理解领域的应用探索。,26
"AMO-Bench: Large Language Models Still Struggle in High School Math
  Competitions",AMO-Bench：大语言模型在高中数学竞赛中仍面临挑战,LLM,Other,https://arxiv.org/pdf/2510.26768,https://huggingface.co/papers/2510.26768,本文提出了AMO-Bench，一套包含50道原创且经专家验证达到国际数学奥林匹克难度的高难度数学题库，旨在更有效评估大型语言模型（LLM）的数学推理能力。实验表明，当前最先进的模型在该测试集上的最高准确率仅为52.4%，大多数模型表现低于40%，显示出LLM在复杂数学问题上的显著不足。研究还发现，增加计算资源有助于提升表现。AMO-Bench为推动语言模型数学推理能力的进一步提升提供了新的基准和研究平台。,25
Surfer 2: The Next Generation of Cross-Platform Computer Use Agents,Surfer 2：下一代跨平台计算机使用智能体,Agent,Other,https://arxiv.org/pdf/2510.19949,https://huggingface.co/papers/2510.19949,本文提出了Surfer 2，一种基于纯视觉观察的统一智能代理架构，能够跨网页、桌面和移动三大环境高效操作。该系统通过层级上下文管理、规划与执行分离及自我校验与恢复机制，实现了长任务的可靠执行。Surfer 2在多个基准测试中表现优异，准确率显著超过现有方法，且无需针对特定任务微调，甚至多次尝试后超越人类表现。研究表明，系统化的协同设计极大提升了基础模型的能力，为通过视觉交互实现通用计算机控制提供了新路径，同时指出了未来视觉语言模型优化的方向。,24
"The Quest for Generalizable Motion Generation: Data, Model, and
  Evaluation",通用运动生成的探索：数据、模型与评估,Diffusion Model,THU,https://arxiv.org/pdf/2510.26794,https://huggingface.co/papers/2510.26794,本文针对3D人体动作生成模型在泛化能力上的瓶颈，提出了一套系统性解决方案。作者构建了包含22.8万高质量动作样本的大规模数据集ViMoGen-228K，融合了动作捕捉数据、网络视频标注及视频生成模型合成样本，丰富了语义多样性。基于此，设计了结合多模态信息的扩散变换模型ViMoGen及其高效轻量版ViMoGen-light，提升生成效果和泛化能力。同时，提出了细粒度评测基准MBench，用于全面评估动作质量和模型表现。实验结果显示该框架显著优于现有方法，推动了动作生成领域的进步。,22
"OmniX: From Unified Panoramic Generation and Perception to
  Graphics-Ready 3D Scenes",OmniX：从统一的全景生成与感知到图形渲染准备的三维场景,Other,Tencent,https://arxiv.org/pdf/2510.26800,https://huggingface.co/papers/2510.26800,本文提出了OmniX，一种统一且高效的框架，利用预训练的二维生成模型实现全景图的感知、生成与补全，从而构建适用于物理渲染、重光照和模拟的高质量三维场景。与传统方法侧重外观生成不同，OmniX能够感知几何形状、纹理及物理材质属性，提升了三维场景的真实感和多样性。作者还构建了大规模多模态合成全景数据集，实验验证了该方法在全景视觉理解和图形级三维场景生成中的有效性，为沉浸式虚拟世界的生成开辟了新路径。,17
"The Era of Agentic Organization: Learning to Organize with Language
  Models",智能体组织时代：学习使用语言模型进行组织,Agent,Microsoft,https://arxiv.org/pdf/2510.26658,https://huggingface.co/papers/2510.26658,本文提出了“代理组织”这一新型人工智能时代的构想，旨在通过多个智能体协作并行解决复杂问题，实现超越单一智能体的能力。为此，作者引入了一种名为“异步思考”的新型推理范式，通过一个组织者动态分配任务给多个工作者，协同完成思考过程，并能通过强化学习优化整体结构。实验证明，该方法在数学推理任务上不仅提升了准确率，还显著降低了推理延迟，同时具备良好的泛化能力，能有效应对未见任务，展示了智能体协作组织的潜力和优势。,17
"Supervised Reinforcement Learning: From Expert Trajectories to Step-wise
  Reasoning",监督强化学习：从专家轨迹到逐步推理,LLM,Other,https://arxiv.org/pdf/2510.25992,https://huggingface.co/papers/2510.25992,本文提出了一种名为监督强化学习（SRL）的新方法，旨在提升小规模语言模型解决多步推理问题的能力。SRL通过让模型在每一步动作前生成内部推理过程，并基于与专家示范动作的逐步相似度给予更细腻的奖励，克服了传统监督微调易过拟合和强化学习难以采样正确解的问题。实验表明，SRL显著优于现有方法，且结合强化学习进一步提升性能。此外，SRL在软件工程等实际任务中也表现出良好的泛化能力，展现了其作为推理导向大模型训练框架的潜力和实用价值。,14
"Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in
  Web Games",智能体能征服网页吗？探索ChatGPT Atlas智能体在网页游戏中的前沿能力,Agent,OpenAI,https://arxiv.org/pdf/2510.26298,https://huggingface.co/papers/2510.26298,本文评估了OpenAI的ChatGPT Atlas在网页游戏中的交互能力，选取了包括Google的T-Rex Runner、数独、Flappy Bird和Stein.world在内的多种浏览器游戏作为测试环境。研究发现，Atlas在逻辑推理类任务如数独中表现优异，完成速度显著超过人类水平；但在需要精准时机和操作控制的实时游戏中表现较差，难以突破初始关卡。结果表明，尽管Atlas具备较强的分析处理能力，但在动态、实时交互的网页环境中仍存在显著局限。该研究为理解和改进智能网页代理在复杂交互任务中的表现提供了重要参考。,14
Automating Benchmark Design,自动化基准设计,LLM,Other,https://arxiv.org/pdf/2510.25039,https://huggingface.co/papers/2510.25039,本文提出了BeTaL框架，旨在自动化设计动态评测基准，以解决当前静态基准易饱和且动态基准难以持续更新的问题。BeTaL通过参数化基准模板的关键设计选项，利用大型语言模型智能调节参数，实现对评测难度和真实性等目标属性的高效控制。实验证明，BeTaL能生成更符合预期难度的新基准，且在多个任务上相较传统方法提升了2-4倍的准确度。该方法为评估不断进步的语言模型提供了更灵活、经济的工具。,10
"EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic
  Health Record Analysis",EHR-R1：一种面向电子健康记录分析的推理增强基础大语言模型,LLM,"Shanghai AI Lab, PKU",https://arxiv.org/pdf/2510.25628,https://huggingface.co/papers/2510.25628,本文提出了EHR-R1，一种专为电子健康记录（EHR）分析设计的大规模语言模型，结合了推理能力以提升临床决策支持。作者构建了包含300万条案例的EHR推理指令数据集EHR-Ins，并基于思维图框架生成高质量推理数据。通过多阶段训练策略，EHR-R1有效整合领域知识与推理技能，实现准确且稳健的EHR分析。同时，论文引入了涵盖42项任务的EHR-Bench基准，全面评估模型表现。实验结果显示，EHR-R1显著优于现有领先模型，在多个任务上取得明显提升，推动了临床相关EHR自动分析的发展。,8
"MIRO: MultI-Reward cOnditioned pretraining improves T2I quality and
  efficiency",MIRO：多重奖励条件预训练提升文本到图像生成的质量与效率,Diffusion Model,Other,https://arxiv.org/pdf/2510.25897,https://huggingface.co/papers/2510.25897,本文提出了一种名为MIRO的多奖励条件预训练方法，用于提升文本生成图像模型的质量和训练效率。与传统方法依赖单一奖励模型进行后期筛选不同，MIRO在训练阶段同时结合多个奖励信号，使模型能够直接学习用户偏好。实验结果表明，该方法显著提升了生成图像的视觉质量和多样性，同时加快了训练速度，在多个用户偏好和组合评测基准上取得了领先表现。该研究为更高效且符合用户需求的图像生成提供了新的思路。,8
"OmniLayout: Enabling Coarse-to-Fine Learning with LLMs for Universal
  Document Layout Generation",OmniLayout：利用大语言模型实现通用文档布局生成的粗到细学习,LLM,Shanghai AI Lab,https://arxiv.org/pdf/2510.26213,https://huggingface.co/papers/2510.26213,本文提出了OmniLayout框架，针对文档布局生成领域中多样化布局数据缺乏的问题，构建了首个涵盖六种常见文档类型、规模达百万的多样化布局数据集OmniLayout-1M。基于此，设计了一个0.5亿参数的语言模型OmniLayout-LLM，采用两阶段的粗到细学习策略，先学习通用布局原则，再迁移到具体领域的细粒度布局生成。实验表明，该方法在多个文档类型上显著优于现有布局生成模型和通用大模型，推动了文档布局生成技术的多领域应用。,7
"Magentic Marketplace: An Open-Source Environment for Studying Agentic
  Markets",Magentic Marketplace：用于研究智能体市场的开源环境,Agent,Microsoft,https://arxiv.org/pdf/2510.25779,https://huggingface.co/papers/2510.25779,本文提出了Magentic Marketplace，一个开放的模拟环境，用于研究由大型语言模型驱动的智能代理在复杂市场中的行为。不同于以往局限于单一任务或双代理互动的研究，该环境模拟了消费者代理与服务代理在多样化经济活动中的双向竞争与协作。实验表明，顶尖模型在理想搜索条件下能接近最优市场福利，但随着规模扩大，性能显著下降，且普遍存在对首个提议的偏好，导致响应速度远比质量更具优势。该研究揭示了智能代理在现实市场中的行为特点，为设计公平高效的智能代理市场提供了重要参考。,4
Reasoning Language Model Inference Serving Unveiled: An Empirical Study,推理语言模型推理服务揭秘：一项实证研究,LLM,THU,https://arxiv.org/pdf/2510.18672,https://huggingface.co/papers/2510.18672,本文系统研究了推理型大语言模型（RLLM）的服务性能，首次揭示了其与传统大语言模型在内存使用、响应延迟、运行时间及领域适应性等方面的显著差异。通过实验证明，部分推理优化技术如模型量化和推测解码能提升服务效率且仅带来轻微准确率损失，而缓存相关方法则可能降低小规模RLLM的性能和准确度。基于真实工作负载的评估进一步验证了这些发现。该研究为RLLM在实际应用中的高效部署提供了重要参考和指导。,3
FullPart: Generating each 3D Part at Full Resolution,FullPart：以全分辨率生成每个三维部件,Diffusion Model,Other,https://arxiv.org/pdf/2510.26140,https://huggingface.co/papers/2510.26140,本文提出了FullPart，一种结合隐式和显式方法的新型三维部件生成框架。该方法首先通过隐式扩散推断部件的边界布局，随后在每个部件独立的高分辨率体素网格中生成细节丰富的三维部件，避免了传统方法中小部件细节不足的问题。同时，引入中心点编码策略解决不同部件尺寸信息交换的对齐难题，保证整体结构一致性。为支持训练，作者还构建了规模最大的人类标注三维部件数据集PartVerse-XL。实验结果表明，FullPart在三维部件生成任务中达到了先进水平，推动了细粒度三维建模的发展。,2
Remote Labor Index: Measuring AI Automation of Remote Work,远程劳动指数：衡量远程工作的AI自动化程度,Agent,Other,https://arxiv.org/pdf/2510.26787,https://huggingface.co/papers/2510.26787,本文提出了远程劳动指数（Remote Labor Index，RLI），这是一个涵盖多个行业的基准测试，旨在评估人工智能在真实经济环境中完成远程工作任务的能力。研究发现，目前AI系统在RLI上的表现较低，最高自动化率仅为2.5%。该指标为量化AI对劳动力自动化影响提供了实证依据，有助于社会各方更准确地理解和应对AI驱动的劳动变革。,2
"MedVLSynther: Synthesizing High-Quality Visual Question Answering from
  Medical Documents with Generator-Verifier LMMs",MedVLSynther：基于生成-验证多模态大语言模型从医学文献合成高质量视觉问答,Multimodal LLM,Amazon,https://arxiv.org/pdf/2510.25867,https://huggingface.co/papers/2510.25867,本文提出了MedVLSynther，一种基于生成-验证框架的方法，自动从开放的生物医学文献中生成高质量的医学视觉问答（VQA）数据。该方法结合图像、图注和文本信息，生成自包含的多项选择题，并通过多阶段验证确保问题的准确性和临床有效性。利用该方法构建的MedSynVQA数据集涵盖多种成像模态和解剖区域。基于此数据训练的多模态模型在多个医学VQA基准上表现优异，展示了该方法在构建大规模、公开、可验证且隐私安全的医学VQA训练数据方面的潜力。,2
Generative View Stitching,生成视角拼接,Diffusion Model,Other,https://arxiv.org/pdf/2510.24718,https://huggingface.co/papers/2510.24718,本文提出了一种名为Generative View Stitching（GVS）的方法，用于基于预定义摄像机轨迹的稳定且无碰撞的视频生成。与传统自回归视频扩散模型只能依赖过去信息不同，GVS通过并行采样整个视频序列，结合过去和未来帧的信息，实现了时间上的一致性和长距离的循环闭合。该方法兼容现有的扩散视频模型，无需额外训练，显著提升了摄像机引导视频生成的质量和稳定性，适用于复杂路径如“不可能楼梯”等场景。,1
"MC-SJD : Maximal Coupling Speculative Jacobi Decoding for Autoregressive
  Visual Generation Acceleration",MC-SJD：用于自回归视觉生成加速的最大耦合推测Jacobi解码,Other,Other,https://arxiv.org/pdf/2510.24211,https://huggingface.co/papers/2510.24211,本文提出了一种名为MC-SJD的无训练、无损失的并行解码框架，用于加速自回归视觉生成。该方法基于最大耦合原理，显著提高了连续迭代中草稿令牌的一致性，解决了现有Speculative Jacobi Decoding在令牌稳定性不足导致接受率降低的问题。MC-SJD仅需对现有算法进行极简修改，便能实现图像生成约4.2倍、视频生成约13.3倍的加速，且不影响生成质量，显著提升了自回归模型在视觉领域的实用性和效率。,1
"EnzyControl: Adding Functional and Substrate-Specific Control for Enzyme
  Backbone Generation",EnzyControl：为酶骨架生成添加功能性和底物特异性控制,AI4Science,Other,https://arxiv.org/pdf/2510.25132,https://huggingface.co/papers/2510.25132,"本论文提出了EnzyControl，一种能够实现功能和底物特异性控制的酶骨架生成方法。为解决现有模型在结合数据和底物特异性控制上的不足，作者构建了包含11,100条实验验证酶-底物对的EnzyBind数据集。EnzyControl通过引入轻量级模块EnzyAdapter，结合多序列比对注释的催化位点和对应底物信息，提升了酶骨架设计的准确性和功能性。实验结果表明，该方法在设计性和催化效率上较基线模型分别提升了13%，显著增强了酶设计的实用价值。相关代码已公开。",1
CRAG-MM: Multi-modal Multi-turn Comprehensive RAG Benchmark,CRAG-MM：多模态多轮综合检索增强生成基准,Multimodal LLM,Meta,https://arxiv.org/pdf/2510.26160,https://huggingface.co/papers/2510.26160,本文提出了CRAG-MM，一个面向多模态多轮对话的综合检索增强生成（RAG）基准，专门针对穿戴设备场景设计。该基准包含6.5千组图像-问题-答案三元组和2千个视觉多轮对话，覆盖13个领域，重点模拟穿戴设备视角下的真实场景和挑战。CRAG-MM设计了单源、多源增强及多轮对话三大任务，并配套检索语料库与接口。实验结果显示现有方法和工业方案在该基准上的表现均有限，表明该领域仍有较大提升空间。该基准已用于KDD Cup 2025，推动了相关技术的发展。,1
"Counteracting Matthew Effect in Self-Improvement of LVLMs through
  Head-Tail Re-balancing",通过头尾重平衡抵消LVLMs自我提升中的马太效应,Multimodal LLM,Other,https://arxiv.org/pdf/2510.26474,https://huggingface.co/papers/2510.26474,本文针对大规模视觉语言模型（LVLMs）自我提升过程中出现的“马太效应”问题——模型在简单任务上表现优异但难以应对复杂任务，导致能力提升不均衡。作者提出了四种有效策略，从数据分布调整和样本重采样两方面入手，实现“头尾”数据的平衡优化。实验结果表明，该方法显著提升了模型的视觉推理能力，平均优于传统自我提升方法3.86分，突破了性能瓶颈，促进了模型在复杂任务上的综合表现。,1
The Quest for Reliable Metrics of Responsible AI,负责任AI可靠指标的探索,AI4Science,Other,https://arxiv.org/pdf/2510.26007,https://huggingface.co/papers/2510.26007,本文探讨了负责任人工智能（AI）发展的关键环节——评估指标的可靠性问题。以推荐系统中的公平性指标为例，作者分析了现有指标在衡量负责任AI进展时的局限性，并总结出一系列指导原则，旨在帮助设计更稳健、可信的评估方法。该研究强调，确保指标本身的可靠性对于推动各类AI应用（包括科学领域的AI）负责任发展至关重要，具有重要的理论和实践意义。,0
"GraphNet: A Large-Scale Computational Graph Dataset for Tensor Compiler
  Research",GraphNet：用于张量编译器研究的大规模计算图数据集,Other,Other,https://arxiv.org/pdf/2510.24035,https://huggingface.co/papers/2510.24035,本文提出了GraphNet，一个包含2700多个真实深度学习计算图的大规模数据集，涵盖六大任务类别并支持多种深度学习框架。为评估张量编译器性能，作者设计了综合考虑运行速度提升和执行正确性的Speedup Score指标，并进一步引入考虑误差的扩展指标Error-aware Speedup Score，帮助识别性能瓶颈。通过对PaddlePaddle和PyTorch默认编译器在视觉和自然语言处理任务上的测试，展示了GraphNet在推动张量编译器优化研究中的实用价值。数据集和评测工具已开源，促进相关领域的系统性研究。,0
ChartAB: A Benchmark for Chart Grounding & Dense Alignment,ChartAB：用于图表定位与密集对齐的基准测试,Multimodal LLM,Other,https://arxiv.org/pdf/2510.26781,https://huggingface.co/papers/2510.26781,本文提出了ChartAlign Benchmark（ChartAB），一个专门用于评估视觉语言模型（VLMs）在图表理解中的表现的新基准。该基准涵盖了从图表中提取数据、定位可视元素到识别多样属性等多项任务，并设计了针对性评测指标和两阶段推理流程，支持对比和对齐多张图表。通过对多款先进模型的测试，揭示了它们在细节感知、鲁棒性及理解偏差等方面的不足，指出了当前模型在图表理解能力上亟需改进的关键方向。该工作为推动图表相关多模态研究提供了重要工具和参考。,0
"CLASS-IT: Conversational and Lecture-Aligned Small-Scale Instruction
  Tuning for BabyLMs",CLASS-IT：面向BabyLMs的对话与讲座对齐小规模指令微调,LLM,Other,https://arxiv.org/pdf/2510.25364,https://huggingface.co/papers/2510.25364,本文探讨了小规模语言模型（100M和140M参数）通过指令调优提升性能的可能性。研究比较了对话式和问答式指令数据集的不同训练策略，评估了模型在微调和零-shot任务中的表现。结果表明，指令调优能在微调任务中带来稳定但有限的提升，且按顺序训练优于混合训练；然而，这些改进未能稳定迁移到零-shot任务，显示出专注交互适应与广泛语言泛化之间的权衡。研究揭示了在人力资源受限条件下，结合多阶段训练策略以提升模型泛化能力的潜力与挑战。,0

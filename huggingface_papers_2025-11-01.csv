标题,中文标题,领域分类,研究机构,PDF链接,论文链接,简明摘要,Upvote数
The End of Manual Decoding: Towards Truly End-to-End Language Models,手动解码的终结：迈向真正的端到端语言模型,LLM,Tencent,https://arxiv.org/pdf/2510.26697,https://huggingface.co/papers/2510.26697,本文提出了AutoDeco，一种能够实现真正端到端文本生成的新型模型架构。该方法通过在每一步动态预测解码参数（如温度和采样概率阈值），使模型能够自我调节生成策略，避免了传统手动调参的繁琐和局限。实验表明，AutoDeco在多个基准测试中显著优于默认解码方法，且性能接近于最佳静态调参的上限。此外，模型还能理解自然语言指令，按需调整生成过程，实现更灵活和可控的文本生成。这为语言模型的交互式和可调节解码开辟了新方向。,87
Emu3.5: Native Multimodal Models are World Learners,Emu3.5：原生多模态模型即世界学习者,Multimodal LLM,Other,https://arxiv.org/pdf/2510.26583,https://huggingface.co/papers/2510.26583,本文提出了Emu3.5，一种大规模多模态世界模型，能够自然地处理和生成视觉与语言交织的信息。该模型通过端到端训练，利用超过10万亿视觉语言数据进行统一预测，支持长时序、多模态内容的生成与理解。通过引入离散扩散适配技术，显著提升了推理速度而不损失性能。Emu3.5展现了强大的多模态推理能力和通用的世界建模能力，能够在多样场景下实现一致的时空理解和开放式交互操作。实验结果显示其在图像生成与编辑任务中表现优异，具备广泛应用潜力。模型已开源，促进社区研究发展。,65
"Kimi Linear: An Expressive, Efficient Attention Architecture",Kimi Linear：一种富表达性且高效的注意力架构,LLM,Other,https://arxiv.org/pdf/2510.26692,https://huggingface.co/papers/2510.26692,本文提出了Kimi Linear，一种结合线性注意力的新型架构，首次在多种任务和场景下实现了优于传统全注意力机制的性能表现。其核心模块Kimi Delta Attention通过改进的门控机制，更高效地利用有限记忆资源，同时采用专门设计的算法显著降低计算成本。实验证明，Kimi Linear在保持训练条件一致的情况下，显著提升了任务表现，减少了缓存使用，并大幅加快了长序列的解码速度。该方法兼具高效性与表现力，可作为全注意力架构的高性能替代方案。论文还开源了相关代码和模型，促进后续研究。,52
"Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in
  Web Games",智能体能征服网络吗？探索ChatGPT Atlas智能体在网页游戏中的前沿能力,Agent,OpenAI,https://arxiv.org/pdf/2510.26298,https://huggingface.co/papers/2510.26298,本文评估了OpenAI ChatGPT Atlas在网页游戏中的交互能力，选取了包括T-Rex Runner、数独、Flappy Bird和Stein.world等多款浏览器游戏作为测试场景。结果显示，Atlas在逻辑推理类任务（如数独）表现优异，完成速度显著快于人类基准；但在需要精准时机和操作的实时游戏中表现较弱，难以突破初级关卡。研究表明，尽管Atlas具备较强的分析处理能力，但在动态、实时交互的网页环境中仍存在明显局限，为未来智能网页代理的发展指明了方向。,40
Exploring Conditions for Diffusion models in Robotic Control,探索扩散模型在机器人控制中的条件设计,Embodied AI,Other,https://arxiv.org/pdf/2510.15510,https://huggingface.co/papers/2510.15510,本文探讨了如何利用预训练的文本到图像扩散模型，为机器人控制任务获取适应性更强的视觉表示。研究发现，直接使用文本条件在机器人控制中效果有限，原因在于模型训练数据与控制环境存在差异。为此，作者提出了ORCA方法，通过引入可学习的任务提示和视觉提示，有效捕捉控制所需的动态细节，从而显著提升了机器人控制的表现。该方法在多个基准测试中达到领先水平，展示了扩散模型在机器人视觉控制领域的潜力。,36
"AMO-Bench: Large Language Models Still Struggle in High School Math
  Competitions",AMO-Bench：大语言模型在高中数学竞赛中仍面临挑战,LLM,Other,https://arxiv.org/pdf/2510.26768,https://huggingface.co/papers/2510.26768,本文提出了AMO-Bench，一个包含50道高难度原创数学题的评测基准，旨在更有效地测试大型语言模型（LLMs）的数学推理能力。相比现有以高中数学竞赛题为基础的评测，AMO-Bench题目难度达到国际数学奥林匹克水平，且仅需给出最终答案，便于自动评分。对26个主流LLMs的测试结果显示，即使表现最好的模型准确率也仅为52.4%，大多数模型低于40%，表明当前模型在高难度数学推理上仍有较大提升空间。该基准的发布有助于推动语言模型推理能力的进一步发展。,30
Surfer 2: The Next Generation of Cross-Platform Computer Use Agents,Surfer 2：下一代跨平台计算机使用智能体,Agent,Other,https://arxiv.org/pdf/2510.19949,https://huggingface.co/papers/2510.19949,本文提出了Surfer 2，一种基于视觉观察的统一架构，能够在网页、桌面和移动三大环境中实现高效的跨平台操作。该系统通过层次化上下文管理、独立的规划与执行机制以及自我验证与自适应恢复，保证了长时间任务的可靠完成。Surfer 2在多个基准测试中表现优异，准确率显著超过现有方法，且无需针对特定任务进行微调，多次尝试后甚至超越人类表现。研究表明，系统化的协同设计能增强基础模型能力，实现仅凭视觉交互的通用计算机控制，推动下一代视觉语言模型的发展。,28
"Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with
  the MME-CoF Benchmark",视频模型准备好作为零样本推理器了吗？基于MME-CoF基准的实证研究,Other,PKU,https://arxiv.org/pdf/2510.26802,https://huggingface.co/papers/2510.26802,本文针对当前先进的视频生成模型在无监督视觉推理任务中的表现进行了系统评估，提出了MME-CoF基准用于测试模型在空间、几何、物理、时间和逻辑等12个维度的推理能力。研究发现，尽管视频模型在短时空间一致性和局部动态推理上表现出一定潜力，但在长时因果推理、严格几何约束和抽象逻辑方面仍存在显著不足。目前它们尚未能作为可靠的零样本推理工具，但可作为辅助视觉引擎，与专门的推理模型结合使用，展现出应用前景。,28
"The Quest for Generalizable Motion Generation: Data, Model, and
  Evaluation",通用运动生成的探索：数据、模型与评估,Diffusion Model,THU,https://arxiv.org/pdf/2510.26794,https://huggingface.co/papers/2510.26794,本文针对3D人体动作生成在泛化能力上的瓶颈，提出了一套系统性框架，通过借鉴视频生成领域的先进经验，从数据、模型和评估三方面推动动作生成技术的发展。作者构建了包含22.8万高质量样本的大规模多模态数据集ViMoGen-228K，设计了融合多源信息的扩散变换模型ViMoGen及其轻量版ViMoGen-light，并引入层次化评测基准MBench以实现细粒度性能评价。实验结果表明，该框架在动作质量和泛化能力上显著优于现有方法，促进了3D动作生成的实用性和多样性。,26
"Supervised Reinforcement Learning: From Expert Trajectories to Step-wise
  Reasoning",监督强化学习：从专家轨迹到逐步推理,LLM,Other,https://arxiv.org/pdf/2510.25992,https://huggingface.co/papers/2510.25992,本文提出了一种名为“监督强化学习”（SRL）的新方法，旨在提升小规模语言模型解决多步推理问题的能力。SRL通过让模型在执行每一步动作前生成内部推理过程，并基于与专家示范的逐步动作相似度给予更细腻的奖励，克服了传统监督微调易过拟合和强化学习难以采样正确解的局限。实验表明，SRL显著优于现有方法，并且与强化学习结合训练能进一步提升性能。此外，SRL在推理和软件工程任务中均表现出良好的泛化能力，展现了其作为推理导向模型训练框架的广泛适用性和有效性。,22
"The Era of Agentic Organization: Learning to Organize with Language
  Models",智能体组织时代：学习使用语言模型进行组织,Agent,Microsoft,https://arxiv.org/pdf/2510.26658,https://huggingface.co/papers/2510.26658,本文提出了“智能组织”这一新型人工智能时代的愿景，强调多个智能体通过协作和并行工作解决复杂问题，超越单一智能体的能力。为实现该目标，作者引入了“异步思维”范式，通过一个动态分配任务、整合中间结果的思考协议，提升推理效率和准确性。实验表明，该方法在数学推理任务中较传统并行思维减少了28%的推理延迟，同时提升了准确率。此外，异步思维具备良好的泛化能力，能有效应对未见过的新任务，无需额外训练。,19
"OmniX: From Unified Panoramic Generation and Perception to
  Graphics-Ready 3D Scenes",OmniX：从统一的全景生成与感知到图形渲染就绪的三维场景,Other,Tencent,https://arxiv.org/pdf/2510.26800,https://huggingface.co/papers/2510.26800,本文提出了OmniX，一种统一且高效的框架，利用预训练的二维生成模型实现全景图的感知、生成与补全，进而构建适用于物理渲染、重新光照和物理模拟的高质量三维场景。OmniX不仅关注外观生成，更能准确感知几何形状和材质属性，提升三维场景的真实感和多样性。作者还构建了大规模多模态全景合成数据集，实验证明该方法在全景视觉理解和图形级三维场景生成方面表现优异，推动了沉浸式虚拟世界的生成技术发展。,17
"MIRO: MultI-Reward cOnditioned pretraining improves T2I quality and
  efficiency",MIRO：多重奖励条件预训练提升文本到图像生成的质量与效率,Diffusion Model,Other,https://arxiv.org/pdf/2510.25897,https://huggingface.co/papers/2510.25897,本文提出了一种名为MIRO的多奖励条件预训练方法，用于提升文本到图像生成模型的质量和训练效率。与传统方法依赖后期单一奖励模型选择不同，MIRO在训练阶段同时利用多个奖励信号，使模型直接学习用户偏好，避免信息丢失和过拟合单一奖励的问题。实验结果表明，MIRO在生成图像的视觉质量、多样性和语义一致性上均有显著提升，同时加快了训练速度，达到了多个用户偏好评测基准的领先水平。该方法为更高效且符合用户需求的图像生成提供了新思路。,11
"EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic
  Health Record Analysis",EHR-R1：一种增强推理能力的基础大语言模型用于电子健康记录分析,LLM,"Shanghai AI Lab, PKU",https://arxiv.org/pdf/2510.25628,https://huggingface.co/papers/2510.25628,本文针对电子健康记录（EHR）分析中存在的任务覆盖有限和推理能力不足的问题，提出了EHR-Ins数据集，包含大量高质量推理指令，覆盖42种EHR任务。基于此，开发了具备推理增强能力的语言模型EHR-R1，采用多阶段训练策略提升领域知识和推理能力，实现准确且稳健的EHR分析。同时，构建了涵盖多任务的新基准EHR-Bench用于评测。实验表明，EHR-R1在多项指标上显著优于现有主流模型，推动了临床EHR自动化分析的可靠性和实用性提升。,9
"OmniLayout: Enabling Coarse-to-Fine Learning with LLMs for Universal
  Document Layout Generation",OmniLayout：利用大语言模型实现通用文档布局生成的粗到细学习,LLM,Shanghai AI Lab,https://arxiv.org/pdf/2510.26213,https://huggingface.co/papers/2510.26213,本文提出了OmniLayout，针对文档布局生成领域中多样化布局数据不足的问题，首次构建了包含六类常见文档类型、规模达百万的多样化布局数据集OmniLayout-1M。基于此，设计了一个0.5亿参数的语言模型OmniLayout-LLM，采用两阶段的粗到细学习策略，先学习通用布局规律，再迁移至具体领域的细粒度布局。实验表明，该方法在多个文档类型上显著优于现有布局生成模型和通用大模型，推动了文档自动排版技术的发展。相关代码和数据集将公开发布。,8
"Magentic Marketplace: An Open-Source Environment for Studying Agentic
  Markets",Magentic Marketplace：用于研究智能体市场的开源环境,Agent,Microsoft,https://arxiv.org/pdf/2510.25779,https://huggingface.co/papers/2510.25779,本文提出了Magentic Marketplace，一个开放源代码的模拟环境，用于研究由大型语言模型驱动的代理在复杂市场中的行为。该环境模拟了消费者代理与服务代理之间的双边互动，帮助分析代理在真实市场条件下的效用、行为偏差及易受操控性。实验结果表明，尽管先进模型在理想搜索条件下能接近最优市场福利，但其性能在大规模环境中显著下降，且普遍存在对首个提议的偏好，导致响应速度远胜于质量。该研究为设计公平高效的智能代理市场提供了重要洞见。,8
"MedVLSynther: Synthesizing High-Quality Visual Question Answering from
  Medical Documents with Generator-Verifier LMMs",MedVLSynther：基于生成-验证多模态大语言模型从医学文献合成高质量视觉问答,Multimodal LLM,Amazon,https://arxiv.org/pdf/2510.25867,https://huggingface.co/papers/2510.25867,本文提出MedVLSynther，一种基于生成器-验证器框架的方法，能从公开的生物医学文献中自动合成高质量的医学视觉问答（VQA）题目。该方法结合图像、图注和文本内容，生成结构化的多项选择题，并通过多阶段验证确保题目自洽、临床有效且图文一致。应用于PubMed Central数据，构建了涵盖多种成像模态和解剖区域的大规模数据集MedSynVQA。基于此数据训练的大型多模态模型在多个医学VQA基准测试中表现优异，体现了该方法在扩展医学视觉问答训练数据方面的可行性和实用价值。,5
Remote Labor Index: Measuring AI Automation of Remote Work,远程劳动指数：衡量远程工作的AI自动化程度,Agent,Other,https://arxiv.org/pdf/2510.26787,https://huggingface.co/papers/2510.26787,本文提出了“远程劳动指数”（Remote Labor Index，RLI），一个涵盖多个行业的综合基准，用于评估人工智能在实际远程工作中的自动化能力。通过在真实且具有经济价值的项目上测试AI代理，结果显示当前AI自动化率仅为2.5%，表明AI在远程工作自动化方面仍处于起步阶段。该指标为理解和跟踪AI对劳动力影响提供了实证依据，帮助各方更有效地应对AI驱动的劳动自动化趋势。,4
"CLASS-IT: Conversational and Lecture-Aligned Small-Scale Instruction
  Tuning for BabyLMs",CLASS-IT：面向BabyLMs的对话与讲座对齐小规模指令微调,LLM,Other,https://arxiv.org/pdf/2510.25364,https://huggingface.co/papers/2510.25364,本文研究了小规模语言模型（约1亿参数）通过指令微调提升性能的可能性。作者比较了对话式与问答式指令数据，采用合并和顺序两种训练策略，并在多种任务上进行评估。结果表明，指令微调在微调任务中带来了稳定但有限的提升，且顺序训练优于合并训练；然而，这些改进未能显著转移到零样本测试中，反映了模型在适应交互能力与保持广泛语言理解之间的权衡。研究强调了在人力和数据受限条件下，结合多阶段课程训练的方法对提升小模型泛化能力的潜力与局限。,4
CRAG-MM: Multi-modal Multi-turn Comprehensive RAG Benchmark,CRAG-MM：多模态多轮综合检索增强生成基准,Multimodal LLM,Meta,https://arxiv.org/pdf/2510.26160,https://huggingface.co/papers/2510.26160,本文提出了CRAG-MM，一个面向多模态多轮对话的综合检索增强生成（RAG）基准，专注于穿戴设备场景下的视觉问答任务。该基准包含6500个图像-问答三元组和2000个多轮对话，涵盖13个领域，模拟真实穿戴设备拍摄的视角，设计了多样的问题类型和图像质量挑战。基准支持单源、多源增强及多轮对话三种任务，并提供相应检索资源和接口。实验结果显示现有方法在该基准上的表现有限，表明该领域仍有较大提升空间。CRAG-MM已成功举办KDD Cup 2025竞赛，推动了多模态问答技术的发展。,3
PORTool: Tool-Use LLM Training with Rewarded Tree,PORTool：基于奖励树的工具使用大语言模型训练,LLM,Other,https://arxiv.org/pdf/2510.26020,https://huggingface.co/papers/2510.26020,本文提出了PORTool，一种基于强化学习的新方法，用于训练具备工具调用能力的大型语言模型。该方法通过构建工具调用步骤的树状结构，针对每一步赋予奖励，鼓励模型探索多种解决路径以获得正确答案。实验覆盖17种工具和多样化查询，结果显示PORTool显著提升了模型的准确率和工具调用效率。该研究为提升语言模型在动态、多步骤工具使用场景中的表现提供了有效策略。,2
"Counteracting Matthew Effect in Self-Improvement of LVLMs through
  Head-Tail Re-balancing",通过头尾重平衡抵消LVLMs自我提升中的马太效应,Multimodal LLM,Other,https://arxiv.org/pdf/2510.26474,https://huggingface.co/papers/2510.26474,本文针对大型视觉语言模型（LVLMs）自我提升过程中出现的“马太效应”问题——模型在简单任务上表现优异但在复杂任务上表现欠佳，导致能力发展不均衡。作者提出了基于分布调整和轨迹重采样的四种策略，实现对简单（头部）和复杂（尾部）任务的平衡优化。实验证明，该方法在多个视觉推理任务中显著提升了模型性能，平均优于传统自我提升方法3.86分，有效缓解了性能瓶颈，推动了LVLMs的全面能力提升。,2
FullPart: Generating each 3D Part at Full Resolution,FullPart：以全分辨率生成每个三维部件,Diffusion Model,Other,https://arxiv.org/pdf/2510.26140,https://huggingface.co/papers/2510.26140,本文提出了FullPart，一种结合隐式和显式方法的三维部件生成框架。该方法通过隐式扩散确定部件的边界布局，再在每个部件的独立高分辨率体素网格中生成细节，解决了以往方法中小部件细节不足的问题。引入的中心点编码策略有效保持了部件间的全局一致性。此外，作者发布了包含4万个物体和32万个部件的最大规模人工标注三维部件数据集PartVerse-XL。实验结果表明，FullPart在三维部件生成任务上达到了领先水平，推动了细节丰富的三维模型合成研究。,2
"EnzyControl: Adding Functional and Substrate-Specific Control for Enzyme
  Backbone Generation",EnzyControl：为酶骨架生成添加功能性和底物特异性控制,AI4Science,Other,https://arxiv.org/pdf/2510.25132,https://huggingface.co/papers/2510.25132,本文针对酶设计中实现底物特异性功能的难题，提出了EnzyControl方法。该方法基于新构建的包含1.1万条酶-底物对的EnzyBind数据库，通过引入一个轻量级模块EnzyAdapter，使预训练的结构生成模型具备底物感知能力，从而生成具有特定催化功能的酶骨架结构。采用两阶段训练策略，显著提升了设计的酶结构的合理性和催化效率。在多个基准测试中，EnzyControl在设计性和催化性能上均优于现有模型，展示了其在定制化酶设计中的潜力和应用价值。,2
"CityRiSE: Reasoning Urban Socio-Economic Status in Vision-Language
  Models via Reinforcement Learning",CityRiSE：通过强化学习在视觉-语言模型中推理城市社会经济状态,Multimodal LLM,THU,https://arxiv.org/pdf/2510.22282,https://huggingface.co/papers/2510.22282,本文提出了CityRiSE，一种结合强化学习的多模态视觉语言模型框架，用于推理和预测城市的社会经济状态。通过引导模型聚焦于语义相关的视觉信息，CityRiSE实现了结构化、目标导向的推理过程，有效提升了社会经济指标的预测准确性和泛化能力，尤其在未知城市和指标上的表现优异。该方法展示了利用公开街景和卫星图像数据，通过强化学习优化视觉语言模型，在城市社会经济感知领域的潜力和应用价值。,1
L^2M^3OF: A Large Language Multimodal Model for Metal-Organic Frameworks,L²M³OF：面向金属有机框架的大型语言多模态模型,Multimodal LLM,Other,https://arxiv.org/pdf/2510.20976,https://huggingface.co/papers/2510.20976,本文提出了L2M3OF，一种首创的多模态大语言模型，专门用于金属有机框架（MOFs）的设计与分析。该模型结合了晶体结构学习与语言理解，能够同时处理结构、文本和知识信息，有效克服了传统语言模型难以表达复杂三维晶体结构的问题。通过构建包含结构-性质-知识的数据库并与领先的闭源模型对比，L2M3OF在性能和知识生成任务上表现优异，且参数量更少。该研究强调了多模态方法在功能材料发现中的重要性，为材料科学领域的智能设计提供了新范式。,1
"Performance Trade-offs of Optimizing Small Language Models for
  E-Commerce",优化小型语言模型在电子商务中的性能权衡,LLM,Other,https://arxiv.org/pdf/2510.21970,https://huggingface.co/papers/2510.21970,本文探讨了使用小型开放权重语言模型在电商领域实现高效意图识别的可行性。通过对一款10亿参数的Llama 3.2模型进行优化和量化处理，研究团队在多语言电商用户查询上实现了与大型模型GPT-4.1相当的99%准确率。性能分析显示，不同硬件环境下优化方法存在显著权衡：GPU量化节省显存但可能降低推理速度，CPU优化则大幅提升速度并减少内存占用。结果表明，经过合理优化的小型模型在特定应用中能以更低计算资源实现顶尖性能，具有广泛应用潜力。,1
POWSM: A Phonetic Open Whisper-Style Speech Foundation Model,POWSM：一种基于Open Whisper风格的语音基础模型,Other,Other,https://arxiv.org/pdf/2510.24992,https://huggingface.co/papers/2510.24992,本文提出了POWSM，一种首个统一的语音基础模型，能够同时完成多种与语音音素相关的任务，包括自动语音识别、音素识别、拼写到音素转换及音素到拼写转换。该模型实现了音频、文本和音素之间的无缝转换，促进了跨语言和低资源环境下的语音处理。实验结果显示，POWSM在保持模型规模的同时，性能优于或匹配现有专用音素识别模型。作者还公开了训练数据和代码，推动开放科学的发展。,0
ChartAB: A Benchmark for Chart Grounding & Dense Alignment,ChartAB：用于图表定位与密集对齐的基准测试,Multimodal LLM,Other,https://arxiv.org/pdf/2510.26781,https://huggingface.co/papers/2510.26781,本文提出了ChartAlign Benchmark（ChartAB），一个专门用于评估视觉语言模型在图表理解任务中的基准。该基准涵盖从图表中提取数据、定位可视元素及识别属性等多项细粒度任务，并设计了专门的评价指标和两阶段推理流程，支持跨图表元素对齐与比较。通过对多款现有模型的测试，研究揭示了它们在图表感知中的偏差、弱点及鲁棒性问题，指出当前模型在细节理解和多图表推理方面的不足，为后续提升视觉语言模型的图表处理能力提供了重要参考。,0
